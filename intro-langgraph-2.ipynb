{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5c8f3d0",
   "metadata": {},
   "source": [
    "## Another example, now with a conditional edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88ce510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6549702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain.chat_models import init_chat_model\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0376ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = init_chat_model(\n",
    "    model=\"openai:gpt-4o\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782cac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessageClassifier(BaseModel):\n",
    "    message_type: Literal[\"emotional\", \"logical\"] = Field(\n",
    "        ...,\n",
    "        description=\"Classify if the message requires an emotional (therapist) or logical response.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ad2477",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    message_type: str | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7624ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_message(state: State):\n",
    "    print('called classify agent and the state has this number of messages:', len(state[\"messages\"]))\n",
    "\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    classifier_llm = llm.with_structured_output(MessageClassifier)\n",
    "\n",
    "    result = classifier_llm.invoke([\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"Classify the user message as either:\n",
    "            - 'emotional': if it asks for emotional support, therapy, deals with feelings, or personal problems\n",
    "            - 'logical': if it asks for facts, information, logical analysis, or practical solutions\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": last_message.content}\n",
    "    ])\n",
    "    return {\"message_type\": result.message_type}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd5b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state: State):\n",
    "    message_type = state.get(\"message_type\", \"logical\")\n",
    "    if message_type == \"emotional\":\n",
    "        return {\"next\": \"therapist\"}\n",
    "\n",
    "    return {\"next\": \"logical\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9030fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def therapist_agent(state: State):\n",
    "\n",
    "    print('called therapist agent and the state has this number of messages:', len(state[\"messages\"]))\n",
    "\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"\"\"You are a compassionate therapist. Focus on the emotional aspects of the user's message.\n",
    "                        Show empathy, validate their feelings, and help them process their emotions.\n",
    "                        Ask thoughtful questions to help them explore their feelings more deeply.\n",
    "                        Avoid giving logical solutions unless explicitly asked.\"\"\"\n",
    "         },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": last_message.content\n",
    "        }\n",
    "    ]\n",
    "    reply = llm.invoke(messages)\n",
    "    return {\"messages\": [{\"role\": \"assistant\", \"content\": reply.content}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecdacd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logical_agent(state: State):\n",
    "\n",
    "    print('called logical agent and the state has this number of messages:', len(state[\"messages\"]))\n",
    "\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"\"\"You are a purely logical assistant. Focus only on facts and information.\n",
    "            Provide clear, concise answers based on logic and evidence.\n",
    "            Do not address emotions or provide emotional support.\n",
    "            Be direct and straightforward in your responses.\"\"\"\n",
    "         },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": last_message.content\n",
    "        }\n",
    "    ]\n",
    "    reply = llm.invoke(messages)\n",
    "    return {\"messages\": [{\"role\": \"assistant\", \"content\": reply.content}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b9fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"classifier\", classify_message)\n",
    "graph_builder.add_node(\"router\", router)\n",
    "graph_builder.add_node(\"therapist\", therapist_agent)\n",
    "graph_builder.add_node(\"logical\", logical_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc347da",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(START, \"classifier\")\n",
    "graph_builder.add_edge(\"classifier\", \"router\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edb3a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_conditional_edges(\n",
    "    \"router\",\n",
    "    lambda state: state.get(\"next\"),\n",
    "    {\"therapist\": \"therapist\", \"logical\": \"logical\"}\n",
    ")\n",
    "\n",
    "graph_builder.add_edge(\"therapist\", END)\n",
    "graph_builder.add_edge(\"logical\", END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3e052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809beb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(\"Error displaying graph:\", e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a35045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_chatbot():\n",
    "    state = {\"messages\": [], \"message_type\": None}\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"Message: \")\n",
    "        if user_input == \"exit\":\n",
    "            print(\"Bye\")\n",
    "            break\n",
    "\n",
    "        state[\"messages\"] = state.get(\"messages\", []) + [\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ]\n",
    "\n",
    "        state = graph.invoke(state)\n",
    "\n",
    "        if state.get(\"messages\") and len(state[\"messages\"]) > 0:\n",
    "            last_message = state[\"messages\"][-1]\n",
    "            print(f\"Assistant: {last_message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07b07a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea7dfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# credits TechWithTim Channel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
